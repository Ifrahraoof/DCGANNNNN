{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.load('C:\\\\Users\\\\USER\\\\dcgan\\\\SampleData_class0.npy')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.5590163 , 0.47438538],\n",
       "        [0.56196624, 0.49151823],\n",
       "        [0.577959  , 0.48218617],\n",
       "        ...,\n",
       "        [0.5349743 , 0.44681278],\n",
       "        [0.5382409 , 0.45190683],\n",
       "        [0.5478018 , 0.4747675 ]],\n",
       "\n",
       "       [[0.5648532 , 0.4683062 ],\n",
       "        [0.5782895 , 0.485152  ],\n",
       "        [0.59625405, 0.4743945 ],\n",
       "        ...,\n",
       "        [0.5380077 , 0.44860727],\n",
       "        [0.54080707, 0.45167008],\n",
       "        [0.5490514 , 0.4725494 ]],\n",
       "\n",
       "       [[0.5595994 , 0.46732464],\n",
       "        [0.5750987 , 0.4816943 ],\n",
       "        [0.5807483 , 0.4719834 ],\n",
       "        ...,\n",
       "        [0.5542868 , 0.47350612],\n",
       "        [0.535008  , 0.46021143],\n",
       "        [0.5571578 , 0.49172395]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.55951655, 0.47556278],\n",
       "        [0.56074107, 0.49245727],\n",
       "        [0.5799179 , 0.48726115],\n",
       "        ...,\n",
       "        [0.54306823, 0.4552346 ],\n",
       "        [0.53776264, 0.4546466 ],\n",
       "        [0.5517503 , 0.4820884 ]],\n",
       "\n",
       "       [[0.5632156 , 0.46940947],\n",
       "        [0.57607675, 0.4816173 ],\n",
       "        [0.58997226, 0.47518623],\n",
       "        ...,\n",
       "        [0.5450856 , 0.4631649 ],\n",
       "        [0.5369293 , 0.45604637],\n",
       "        [0.55333066, 0.48144874]],\n",
       "\n",
       "       [[0.5629252 , 0.46703672],\n",
       "        [0.578421  , 0.48380747],\n",
       "        [0.5906947 , 0.472718  ],\n",
       "        ...,\n",
       "        [0.54556495, 0.4569102 ],\n",
       "        [0.54370517, 0.45707768],\n",
       "        [0.5525841 , 0.4779569 ]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape=data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1500, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-0223d6a38c50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msizee\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "sizee=labels.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sizee' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5dbc4f15a8f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msizee\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sizee' is not defined"
     ]
    }
   ],
   "source": [
    "sizee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load('C:\\\\Users\\\\USER\\\\dcgan\\\\SampleData_class0_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape=labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = labels.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-58546bd16aaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\\\Users\\\\USER\\\\Superdataset\\\\Training_data.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('C:\\\\Users\\\\USER\\\\Superdataset\\\\Training_data.csv', header=None)\n",
    "train_data = np.array(train_data).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=np.reshape(train_data,train_data.shape+(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=train_data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimm=train_data.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape=train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv('C:\\\\Users\\\\USER\\\\Superdataset\\\\Training_labels.csv', header=None)\n",
    "train_labels = np.array(train_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizel=train_labels.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape=train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di=train_labels.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=np.reshape(train_labels,17388)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.load('C:\\\\Users\\\\USER\\\\DATASET\\\\Training\\\\A01T.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<numpy.lib.npyio.NpzFile at 0x1b8993f4cd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('C:\\\\Users\\\\USER\\\\dcgan\\\\SampleData_class0.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.reshape(data,(10,1500*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=data.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# First read into csv with pandas\n",
    "s_data = pd.read_csv(\"C:\\\\Users\\\\USER\\\\Superdataset\\\\Training_data.csv\")\n",
    " # Save numpy as npy\n",
    "np.save(\"C:\\\\Users\\\\USER\\\\Superdataset\\\\Training_data.npy\", s_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# First read into csv with pandas\n",
    "s_labels = pd.read_csv(\"C:\\\\Users\\\\USER\\\\Superdataset\\\\Training_labels.csv\")\n",
    " # Save numpy as npy\n",
    "np.save(\"C:\\\\Users\\\\USER\\\\Superdataset\\\\Training_labels.npy\", s_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_class0 = [np.load('C:\\\\Users\\\\USER\\\\Superdataset\\\\Training_data.npy')] \n",
    "data_class0 = np.concatenate(data_class0) \n",
    "label_class0 = [np.load('C:\\\\Users\\\\USER\\\\Superdataset\\\\Training_labels.npy')] \n",
    "label_class0 = np.concatenate(label_class0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python EEG_DCGAN[1].py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Namespace' object has no attribute 'nz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c723ac0dbb10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdropout_level\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mnz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mweights_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Namespace' object has no attribute 'nz'"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "opt = parser.parse_args(args=[])\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "device  = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "batch_size = 5\n",
    "learning_rate = 0.0001\n",
    "dropout_level = 0.05\n",
    "nz = opt.nz\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.zeros_(m.bias)  \n",
    "\n",
    "\n",
    "class EEG_CNN_Generator(nn.Module): \n",
    "    def __init__(self): \n",
    "        super(EEG_CNN_Generator, self).__init__() \n",
    " \n",
    "        self.nz = nz \n",
    "        self.layer1 = nn.Sequential( \n",
    "            nn.Linear(self.nz, 640), \n",
    "            nn.PReLU() \n",
    "        ) \n",
    "        self.layer2 = nn.Sequential( \n",
    "            nn.ConvTranspose1d(in_channels=16, out_channels=16, kernel_size=22, stride=4),  \n",
    "            nn.PReLU() \n",
    "        ) \n",
    "        self.layer3 = nn.Sequential( \n",
    "            nn.ConvTranspose1d(in_channels=16, out_channels=16, kernel_size=18, stride=2), \n",
    "            nn.PReLU() \n",
    "        ) \n",
    "        self.layer4 = nn.Sequential( \n",
    "            nn.ConvTranspose1d(in_channels=16, out_channels=2, kernel_size=16, stride=4), \n",
    "            nn.Sigmoid() \n",
    "        ) \n",
    " \n",
    "    def forward(self, z): \n",
    "        out = self.layer1(z) \n",
    "        out = out.view(out.size(0), 16, 40) \n",
    "        out = self.layer2(out) \n",
    "        out = self.layer3(out) \n",
    "        out = self.layer4(out) \n",
    "        return out \n",
    "\n",
    "class EEG_CNN_Discriminator(nn.Module): \n",
    "    def __init__(self): \n",
    "        super(EEG_CNN_Discriminator, self).__init__() \n",
    " \n",
    "        self.layer1 = nn.Sequential( \n",
    "            nn.Conv1d(in_channels=2, out_channels=16, kernel_size=10, stride = 2), \n",
    "            nn.BatchNorm1d(num_features=16), \n",
    "            nn.LeakyReLU(0.2), \n",
    "            nn.MaxPool1d(2)) \n",
    "        self.dense_layers = nn.Sequential( \n",
    "            nn.Linear(5968, 600), \n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(600, 1)) \n",
    " \n",
    "    def forward(self, x): \n",
    "        out = self.layer1(x) \n",
    "        out = out.view(out.size(0), -1) \n",
    "        out = self.dense_layers(out)      \n",
    "        return out \n",
    "\n",
    "\n",
    "def dcgan(datatrain, label, nseed):\n",
    "\n",
    "    random.seed(nseed)\n",
    "    np.random.seed(nseed)\n",
    "    torch.manual_seed(nseed)\n",
    "    torch.cuda.manual_seed(nseed)\n",
    "\n",
    "    datatrain = torch.from_numpy(datatrain)\n",
    "    label = torch.from_numpy(label)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(datatrain, label)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    generator = EEG_CNN_Generator().to(device)\n",
    "    discriminator = EEG_CNN_Discriminator().to(device)\n",
    "    discriminator.apply(weights_init)\n",
    "    generator.apply(weights_init)\n",
    "\n",
    "    # Loss function\n",
    "    adversarial_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer_Gen = torch.optim.Adam(generator.parameters(), lr=learning_rate, betas=(opt.b1, opt.b2))\n",
    "    optimizer_Dis = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "\n",
    "    Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "\n",
    "    real_label = 1\n",
    "    fake_label = 0\n",
    "    batches_done = 0\n",
    "    new_data = []\n",
    "    global_step = 0\n",
    "\n",
    "    # GAN Training ---------------------------------------------------------------\n",
    "    discriminator.train()\n",
    "    generator.train()\n",
    "    for epoch in range(opt.n_epochs):\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            imgs, _ = data\n",
    "            imgs = imgs.to(device)\n",
    "            \n",
    "            # Configure input\n",
    "            real_data = imgs.type(Tensor)\n",
    "            label = torch.ones(imgs.shape[0], 1).to(device)\n",
    "            z = torch.randn(imgs.shape[0], nz).to(device)\n",
    "\n",
    "            if i % 5 == 0:\n",
    "                # print('Discriminator')\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "\n",
    "                ############################\n",
    "                # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "                ###########################\n",
    "\n",
    "                # train with real\n",
    "                optimizer_Dis.zero_grad()\n",
    "                output_real = discriminator(real_data)\n",
    "\n",
    "                # Calculate error and backpropagate\n",
    "                errD_real = adversarial_loss(output_real, label)\n",
    "                errD_real.backward()\n",
    "\n",
    "                # train with fake        \n",
    "                # Generate fake data\n",
    "                fake_data = generator(z)\n",
    "                label = torch.zeros(imgs.shape[0], 1).to(device)\n",
    "                output_fake = discriminator(fake_data)\n",
    "                errD_fake = adversarial_loss(output_fake, label)\n",
    "                errD_fake.backward()\n",
    "                errD = errD_real + errD_fake\n",
    "                optimizer_Dis.step()\n",
    "\n",
    "            # Train the generator every n_critic steps\n",
    "            if i % 1 == 0:\n",
    "                # print('Generator')\n",
    "                # -----------------\n",
    "                #  Train Generator\n",
    "                # -----------------\n",
    "\n",
    "                ############################\n",
    "                # (2) Update G network: maximize log(D(G(z)))\n",
    "                ###########################\n",
    "                z = torch.randn(imgs.shape[0], nz).to(device)\n",
    "                fake_data = generator(z)\n",
    "                \n",
    "                # Reset gradients\n",
    "                optimizer_Gen.zero_grad()\n",
    "\n",
    "                output = discriminator(fake_data)\n",
    "                bceloss = adversarial_loss(output, torch.ones(imgs.shape[0], 1).to(device))\n",
    "                errG = bceloss\n",
    "                errG.backward()\n",
    "                optimizer_Gen.step()\n",
    "\n",
    "            print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] \" % (epoch, opt.n_epochs, i, len(dataloader), errD.item(), errG.item(), ))\n",
    "\n",
    "\n",
    "    # generate the data\n",
    "    discriminator.eval()\n",
    "    generator.eval()\n",
    "    for epoch in range(100):\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            imgs, _ = data\n",
    "            imgs = imgs.to(device)\n",
    "            real_data = imgs.type(Tensor)\n",
    "            z = torch.randn(imgs.shape[0], nz).to(device)\n",
    "\n",
    "            fake_data = generator(z)\n",
    "            \n",
    "            output = discriminator(fake_data)\n",
    "            \n",
    "            if i % opt.sample_interval == 0:\n",
    "                # print (batches_done % opt.sample_interval) \n",
    "                fake_data = fake_data.data[:25].cpu().numpy()\n",
    "                new_data.append(fake_data)\n",
    "\n",
    "    new_data = np.concatenate(new_data) \n",
    "    new_data = np.asarray(new_data)\n",
    "    print (new_data.shape)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "run EEG_DCGAN[1].py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in c:\\users\\user\\anaconda3\\lib\\site-packages (5.3.4)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipykernel) (6.0.4)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipykernel) (6.1.7)\n",
      "Requirement already satisfied: ipython>=5.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipykernel) (7.19.0)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipykernel) (5.0.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel) (2.8.1)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel) (19.0.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel) (4.6.3)\n",
      "Requirement already satisfied: pygments in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel) (2.7.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel) (3.0.8)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel) (4.4.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel) (50.3.1.post20201107)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel) (0.4.4)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel) (0.7.5)\n",
      "Requirement already satisfied: backcall in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel) (0.17.1)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\user\\anaconda3\\lib\\site-packages (from traitlets>=4.1.0->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->jupyter-client->ipykernel) (1.15.0)\n",
      "Requirement already satisfied: pywin32>=1.0; sys_platform == \"win32\" in c:\\users\\user\\anaconda3\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel) (227)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel) (0.2.5)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel) (0.7.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit EEG_DCGAN[1].py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
